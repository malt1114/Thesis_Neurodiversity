{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3a76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor, argmax, randn\n",
    "from torch.nn import CrossEntropyLoss, BCELoss, NLLLoss, LogSoftmax\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6d59ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data.nosync/networks_multi/1320247_run-1_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data.nosync/networks_multi/8415034_run-2_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data.nosync/networks_multi/3011311_run-2_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data.nosync/networks_multi/0010087_run-2_ADHD2...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data.nosync/networks_multi/0010030_run-2_ADHD2...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>data.nosync/networks_multi/0010115_run-1_ADHD2...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>data.nosync/networks_multi/0010086_run-2_ADHD2...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>data.nosync/networks_multi/1127915_run-1_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>data.nosync/networks_multi/2136051_run-1_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>data.nosync/networks_multi/0010053_run-2_ADHD2...</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file diagnosis\n",
       "0    data.nosync/networks_multi/1320247_run-1_ADHD2...        TD\n",
       "1    data.nosync/networks_multi/8415034_run-2_ADHD2...        TD\n",
       "2    data.nosync/networks_multi/3011311_run-2_ADHD2...        TD\n",
       "3    data.nosync/networks_multi/0010087_run-2_ADHD2...      ADHD\n",
       "4    data.nosync/networks_multi/0010030_run-2_ADHD2...      ADHD\n",
       "..                                                 ...       ...\n",
       "436  data.nosync/networks_multi/0010115_run-1_ADHD2...      ADHD\n",
       "437  data.nosync/networks_multi/0010086_run-2_ADHD2...      ADHD\n",
       "438  data.nosync/networks_multi/1127915_run-1_ADHD2...        TD\n",
       "439  data.nosync/networks_multi/2136051_run-1_ADHD2...        TD\n",
       "440  data.nosync/networks_multi/0010053_run-2_ADHD2...        TD\n",
       "\n",
       "[441 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = pd.read_csv(f'data.nosync/networks_multi/train_set_files.csv')\n",
    "train_list['diagnosis'] = train_list['file'].apply(lambda x: x.split('_')[4])\n",
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75438827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diagnosis': ['ADHD', 'ASD', 'ASD-ADHD', 'TD'],\n",
       " 'file': [143, 58, 23, 217],\n",
       " 'total': [441, 441, 441, 441],\n",
       " 'prob': [0.3242630385487528,\n",
       "  0.13151927437641722,\n",
       "  0.05215419501133787,\n",
       "  0.49206349206349204]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist = train_list.groupby('diagnosis').count().reset_index()\n",
    "train_dist['total'] = train_dist['file'].sum()\n",
    "train_dist['prob'] = train_dist['file']/train_dist['total']\n",
    "train_dist = train_dist.to_dict(orient = 'list')\n",
    "train_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41fa3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For uniform probabilities: 1.3862946033477783\n",
      "For prior probabilities: 1.1349709033966064\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "uniform_prob = []\n",
    "prior_prob = []\n",
    "for i in range(4):\n",
    "    y = [float(0) for i in range(4)]\n",
    "    y[i] = float(1)\n",
    "    for n in range(train_dist['file'][i]):\n",
    "        true_labels.append(y)\n",
    "        uniform_prob.append([0.25 for i in range(4)])\n",
    "        prior_prob.append(train_dist['prob'])\n",
    "\n",
    "true_labels = tensor(true_labels)\n",
    "uniform_prob = tensor(uniform_prob)\n",
    "prior_prob = tensor(prior_prob)\n",
    "\n",
    "log_prior_prob = prior_prob.log()\n",
    "log_uniform_prob = uniform_prob.log()\n",
    "\n",
    "loss_func = NLLLoss()\n",
    "print(f\"For uniform probabilities: {loss_func(log_uniform_prob, argmax(true_labels, dim=-1))}\")\n",
    "print(f\"For prior probabilities: {loss_func(log_prior_prob, argmax(true_labels, dim=-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162beee",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16ace6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diagnosis': ['Non-TD', 'TD'],\n",
       " 'file': [224, 217],\n",
       " 'total': [441, 441],\n",
       " 'prob': [0.5079365079365079, 0.49206349206349204]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist = train_list.copy()\n",
    "train_dist['diagnosis'] = train_dist['diagnosis'].replace({'ADHD': 'Non-TD',\n",
    "                                                           'ASD': 'Non-TD',\n",
    "                                                           'ASD-ADHD': 'Non-TD'})\n",
    "train_dist = train_dist.groupby('diagnosis').count().reset_index()\n",
    "train_dist['total'] = train_dist['file'].sum()\n",
    "train_dist['prob'] = train_dist['file']/train_dist['total']\n",
    "train_dist = train_dist.to_dict(orient = 'list')\n",
    "train_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e9b15af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For uniform probabilities: 0.6931471824645996\n",
      "For prior probabilities: 0.6930211186408997\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "uniform_prob = []\n",
    "prior_prob = []\n",
    "for i in range(2):\n",
    "    y = [float(0) for i in range(2)]\n",
    "    y[i] = float(1)\n",
    "    for n in range(train_dist['file'][i]):\n",
    "        true_labels.append(y)\n",
    "        uniform_prob.append([0.5 for i in range(2)])\n",
    "        prior_prob.append(train_dist['prob'])\n",
    "\n",
    "true_labels = tensor(true_labels)\n",
    "uniform_prob = tensor(uniform_prob)\n",
    "prior_prob = tensor(prior_prob)\n",
    "\n",
    "loss_func = BCELoss()\n",
    "print(f\"For uniform probabilities: {loss_func(uniform_prob, true_labels)}\")\n",
    "print(f\"For prior probabilities: {loss_func(prior_prob, true_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b38997",
   "metadata": {},
   "source": [
    "## Participant split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99b01413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>participant</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>87</td>\n",
       "      <td>27.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASD</td>\n",
       "      <td>58</td>\n",
       "      <td>18.238994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASD-ADHD</td>\n",
       "      <td>23</td>\n",
       "      <td>7.232704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TD</td>\n",
       "      <td>150</td>\n",
       "      <td>47.169811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  participant    percent\n",
       "0      ADHD           87  27.358491\n",
       "1       ASD           58  18.238994\n",
       "2  ASD-ADHD           23   7.232704\n",
       "3        TD          150  47.169811"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = pd.read_csv(f'data.nosync/networks_multi/train_set_files.csv')\n",
    "train_list['participant'] = train_list['file'].apply(lambda x: x.split('/')[2])\n",
    "train_list['participant'] = train_list['participant'].apply(lambda x: x.split('_')[0] + '-' + x.split('_')[2])\n",
    "train_list['diagnosis'] = train_list['file'].apply(lambda x: x.split('_')[4])\n",
    "train_list = train_list.drop_duplicates('participant')[['participant', 'diagnosis']].groupby('diagnosis').count().reset_index()\n",
    "train_list['percent'] = train_list['participant']/train_list['participant'].sum()*100\n",
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4efb0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>participant</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>20</td>\n",
       "      <td>29.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASD</td>\n",
       "      <td>11</td>\n",
       "      <td>16.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASD-ADHD</td>\n",
       "      <td>5</td>\n",
       "      <td>7.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TD</td>\n",
       "      <td>32</td>\n",
       "      <td>47.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  participant    percent\n",
       "0      ADHD           20  29.411765\n",
       "1       ASD           11  16.176471\n",
       "2  ASD-ADHD            5   7.352941\n",
       "3        TD           32  47.058824"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list = pd.read_csv(f'data.nosync/networks_multi/val_set_files.csv')\n",
    "val_list['participant'] = val_list['file'].apply(lambda x: x.split('/')[2])\n",
    "val_list['participant'] = val_list['participant'].apply(lambda x: x.split('_')[0] + '-' + x.split('_')[2])\n",
    "val_list['diagnosis'] = val_list['file'].apply(lambda x: x.split('_')[4])\n",
    "val_list = val_list.drop_duplicates('participant')[['participant', 'diagnosis']].groupby('diagnosis').count().reset_index()\n",
    "val_list['percent'] = val_list['participant']/val_list['participant'].sum()*100\n",
    "val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f81f9636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>participant</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>20</td>\n",
       "      <td>29.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASD</td>\n",
       "      <td>11</td>\n",
       "      <td>16.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASD-ADHD</td>\n",
       "      <td>5</td>\n",
       "      <td>7.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TD</td>\n",
       "      <td>32</td>\n",
       "      <td>47.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  participant    percent\n",
       "0      ADHD           20  29.411765\n",
       "1       ASD           11  16.176471\n",
       "2  ASD-ADHD            5   7.352941\n",
       "3        TD           32  47.058824"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = pd.read_csv(f'data.nosync/networks_multi/test_set_files.csv')\n",
    "test_list['participant'] = test_list['file'].apply(lambda x: x.split('/')[2])\n",
    "test_list['participant'] = test_list['participant'].apply(lambda x: x.split('_')[0] + '-' + x.split('_')[2])\n",
    "test_list['diagnosis'] = test_list['file'].apply(lambda x: x.split('_')[4])\n",
    "test_list = test_list.drop_duplicates('participant')[['participant', 'diagnosis']].groupby('diagnosis').count().reset_index()\n",
    "test_list['percent'] = test_list['participant']/test_list['participant'].sum()*100\n",
    "test_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
